Build me a minimal personal website that feels like a Gen AI chat interface.

Tech stack
1. React + Vite + TypeScript front end in /client
2. TailwindCSS for styling
3. Node 20 + Express in /server
4. No database
5. One POST endpoint /api/ask that proxies to OpenRouter
6. Project must run locally with Node, and must be easy to deploy anywhere that can run Node. Do not depend on Replit specific shims.

Visual style and theme
1. Default state should be "light mode," which is the initial theme value in code.
2. The default theme background uses the color #151619. Treat this as the base page background for the initial render.
3. Text in the default theme should be light gray or white so it reads well on #151619.
4. Accent color for identity elements is a deep blue pill. Use this color for my intro bubble and for the "NW" badge.
5. Provide a sticky light or dark mode toggle in the top right. Clicking it swaps the theme tokens by flipping background and text.
   - For alternate theme, invert basics. Background goes near white, text goes near black, accent blue can stay the same.
   - The toggle itself is always visible in the top right while scrolling.
6. All color tokens should live in a small theme context or hook so we can later extend, for example:
   BACKGROUND_BASE = "#151619"
   TEXT_PRIMARY_LIGHT = "#ffffff"
   TEXT_PRIMARY_DARK = "#000000"
   ACCENT_BLUE = something like "#002d6e" or similar deep blue
   You can refine exact shades, but BACKGROUND_BASE must be #151619.

Layout and persistent chrome
1. Top left: a fixed small pill with "NW"
   - Background is ACCENT_BLUE
   - Text is white
   - Rounded corners
   - This pill does not move when you scroll
2. Top right: the light or dark mode toggle control
   - Icon only (sun or moon)
   - This control is sticky and always visible
3. The whole page background should use BACKGROUND_BASE from the active theme
4. All layout must be responsive first. Use Tailwind breakpoints instead of hard coded pixel values.
   - Mobile: stacked vertical, input bar spans almost full width with safe margin
   - Desktop: centered column with max width around 700 px for chat bubbles
   - Do not lock width to desktop values

Landing sequence on first load
1. Center top of the content area:
   - Circular profile image. Use /client/src/assets/profile.jpg
   - White ring border and subtle shadow
2. Under the profile image, render one system bubble:
   - Rectangle with ACCENT_BLUE background
   - White text: "Hi, I'm Nick!"
   - The bubble is centered under the profile image
3. Immediately after that bubble, show a short pulse or typing indicator for about 600 ms
4. After that delay, simulate streaming of a longer markdown answer which is my intro. The stream should look like the site is typing.
   - You do not need server side streaming. Simulate in the browser by revealing characters over time, for example 20 to 30 characters per second.
   - While streaming, render markdown progressively.
   - When complete, leave the final rendered markdown in place as a normal assistant style bubble

Intro markdown content
Store this long intro answer in /client/src/content/intro.ts as a markdown string. Render it as the "assistant" answer. The bubble should be left aligned, with max width ~700 px, and good line height.

"About Nick

I'm an AI engineer with 5 plus years of experience and more than 20 patents. I focus on building reliable, scalable systems that move from prototype to product without losing clarity or purpose. I work on retrieval augmented generation pipelines, multi agent systems, and internal AI platforms that help real teams get work done.

I like to learn new tech quickly and apply it to real problems, not just demos. Outside work I'm usually exploring the city, traveling, lifting, or hunting down the best latte in town.

Experience

Software Engineer II, OCTO Engineering, Dell Technologies (2023 to Present)
I work on AI systems, distributed services, and internal enablement tools. I have shipped work across MLOps pipelines, ONNX Runtime optimization, and agent style systems that automate complex internal workloads. A lot of my work has focused on retrieval augmented generation and multi agent platforms that help teams use AI effectively. I have contributed to more than 20 patents in AI and systems design.

Software Engineer I, Client CTO Engineering, Dell Technologies (2021 to 2023)
I worked on on device intelligence and connected device concepts. Projects ranged from telemetry automation for local model training to early input and design work for the NYX controller and related edge experiences. Some of that work started as fast proof of concept and ended up influencing product direction.

Earlier work
Software Engineering Intern, Tech Strategy Team, Dell Technologies (2020)
I helped develop a touchpad concept with hardware level video conferencing controls, which later showed up in shipping Dell devices.

Data Science Intern, ThoughtTrace (2018)
I helped automate training and validation for document classifiers on oil and gas lease data, focusing on dataset quality and retraining speed.

Peer Teacher, Electrical Engineering, Texas A and M University (2019)
I taught computer systems fundamentals and supported lab instruction for undergrads.

Contact
nickrwann@gmail.com
Austin, TX
"

After this intro finishes streaming, show the chat input bar at the bottom.

Chat input bar
1. The input bar sits bottom center of the viewport. On desktop it floats with rounded corners and a subtle shadow. On mobile it snaps near the bottom with proper safe area padding.
2. Bar layout from left to right:
   - A small refresh icon button
   - A plus icon
   - A single line text field
   - A microphone icon (not functional yet)
   - A purple circular send button
3. Placeholder text should say:
   - "Ask anything"
   - or "Ask a question about Nick..."
4. Character limit:
   - Hard cap at 250 characters
   - Show a live counter like "124 / 250" under the input or aligned to the right inside the bar
   - If the user types beyond 250, block further input
   - Also enforce this limit in the backend
5. Prompt suggestions:
   - Above the bar or just above the input, render four small clickable suggestion pills
     - "Why should I hire Nick?"
     - "What is Nick best at?"
     - "What does Nick do in his free time?"
     - "Ask a question about Nick..."
   - Clicking a pill should fill the input with that text and focus the field

Question and answer flow
1. When the user hits send:
   - Disable the input field and the send button
   - Capture the user's text
   - Clear the main chat viewport so we are not building thread history. This is a single shot answer model.
     - You may keep the profile picture and "Hi, I'm Nick!" header row, or you may hide it to reduce noise. Pick one and implement it consistently.
   - Show a "user bubble" with their question
   - Under it, show a loader bubble for the assistant
   - Call POST /api/ask on the Express backend with body { question: userText }
   - When the backend responds, simulate streaming the answer into the assistant bubble using the same character by character effect as the intro
   - When streaming is done, re enable the input for another question
2. We do not keep multi turn memory. Every question is treated like the first question.
3. The refresh icon button should wipe the viewport and replay the original landing sequence:
   - profile picture
   - "Hi, I'm Nick!"
   - intro streaming markdown

Responsive requirements
1. All UI must work on mobile and desktop with no code changes
   - Use flexbox and Tailwind responsive classes
   - Use max width containers like max-w-screen-md or max-w-[700px] for chat bubbles on desktop
   - On mobile, bubbles should still have readable padding and full width minus margin
2. The top left NW pill and top right theme toggle must not overlap the chat bubbles on very small screens. Add safe margins.
3. The floating bottom input bar must not be cut off by the iOS Safari toolbar. Add bottom padding using env(safe-area-inset-bottom) if available.

Express backend
1. Create /server/index.ts that:
   - Sets up an Express app
   - Uses JSON body parsing and CORS in dev
   - Mounts POST /api/ask
   - Exposes GET /health for debugging
   - Listens on process.env.PORT or 8000 by default
2. POST /api/ask should look like this in TypeScript:

   import express from "express";
   import fetch from "node-fetch";
   import { SYSTEM_PROMPT } from "./prompt.js";

   const router = express.Router();

   router.post("/ask", async (req, res) => {
     try {
       const { question } = req.body || {};

       if (!question || typeof question !== "string") {
         return res.status(400).json({ message: "Missing 'question' in request body" });
       }

       if (question.length > 250) {
         return res.status(400).json({ message: "Question too long. Max 250 characters." });
       }

       const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
         method: "POST",
         headers: {
           "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY_2}`,
           "Content-Type": "application/json",
           "X-Title": "NW Portfolio Website"
         },
         body: JSON.stringify({
           model: "mistralai/mistral-small-3.2-24b-instruct:free",
           messages: [
             { role: "system", content: SYSTEM_PROMPT },
             { role: "user", content: question }
           ]
         })
       });

       if (!response.ok) {
         const errText = await response.text();
         console.error("OpenRouter API error:", errText);
         return res.status(response.status).json({
           message: "Error from OpenRouter API",
           details: errText
         });
       }

       const data = await response.json();
       return res.json({
         answer: data.choices?.[0]?.message?.content || "No response received."
       });
     } catch (err) {
       console.error("Internal error in /api/ask:", err);
       return res.status(500).json({ message: "Error processing question" });
     }
   });

   export default router;

3. SYSTEM_PROMPT should live in /server/prompt.ts. It tells the model to answer as if it is me, and to stay focused on professional and personal background only.

   Example:
   "You are Nick Wanner's portfolio assistant. You answer questions about Nick's skills, background, interests, and work. You speak in plain language. You keep answers under 200 words. If asked something unrelated to Nick, politely steer back to Nick."

Build targets and portability
1. dev mode
   - Run Vite for the client on port 5173
   - Run Express on port 8000
   - Client should call the backend at http://localhost:8000/api/ask
   - Enable CORS in dev
   - This should work on any machine with Node 20 or higher
2. prod mode
   - Build the client to static assets with Vite
   - Express should serve the built client from /dist
   - Express should also continue to expose /api/ask
   - In prod we do not need CORS because UI and API come from the same origin
3. All config must live in environment variables and code, not in Replit specific files
   - OPENROUTER_API_KEY_2 for the backend
4. I should be able to run this locally on my laptop with:
   - npm install in both /client and /server
   - npm run dev in parallel for dev mode
   - Then build and run as a single Node process for prod mode
5. I should also be able to host this on any Node friendly host, or in a simple container, without changing code

Deliverables
1. A working project with:
   - /client React Vite app
   - /server Express app
   - Tailwind configured
   - placeholder profile image in /client/src/assets/profile.jpg
   - intro markdown content in /client/src/content/intro.ts
   - a ChatScreen component that handles:
     a. showing the profile image, greeting bubble, and intro streaming
     b. showing the single question flow
     c. refresh button that replays the intro flow
     d. 250 character limit with live counter
     e. clickable suggestion pills
   - a ThemeToggle component pinned top right that flips theme tokens and updates BACKGROUND_BASE, text colors, etc
   - a small fixed "NW" badge pinned top left
2. The site should open and immediately feel like talking to an AI version of me. It should teach who I am and what I work on without the user needing to scroll through a resume.
